{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "\n",
        "    import torch_geometric\n",
        "except ImportError:\n",
        "    !pip install torch_geometric"
      ],
      "metadata": {
        "id": "BqUlWimSWkXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9afde86c-bb52-4434-ac09-e32265802808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMaR-En0MT-y",
        "outputId": "51a7d9ed-7464-42d3-9d82-80ee738bfd97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Random Forest Metrics\n",
            "Accuracy:  0.4545\n",
            "F1-score:  0.3500\n",
            "Precision: 0.3125\n",
            "Recall:    0.5000\n",
            "nDCG:      0.7590\n",
            "\n",
            "üìä Popularity-Based Metrics\n",
            "Accuracy:  0.2424\n",
            "F1-score:  0.0976\n",
            "Precision: 0.0606\n",
            "Recall:    0.2500\n",
            "nDCG:      0.6368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä GCN Metrics\n",
            "Accuracy:  0.4953\n",
            "F1-score:  0.3750\n",
            "Precision: 0.3333\n",
            "Recall:    0.5000\n",
            "nDCG:      0.7807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä DAGNN Metrics\n",
            "Accuracy:  0.4206\n",
            "F1-score:  0.3209\n",
            "Precision: 0.3258\n",
            "Recall:    0.4231\n",
            "nDCG:      0.7381\n",
            "\n",
            "üìä GAT Metrics\n",
            "Accuracy:  0.3271\n",
            "F1-score:  0.2248\n",
            "Precision: 0.3182\n",
            "Recall:    0.3269\n",
            "nDCG:      0.6849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# dagnn_recommender_comparison.py\n",
        "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ 5 –º–æ–¥–µ–ª–µ–π: Popularity, Random Forest, GCN, DAGNN, GAT –Ω–∞ –≥—Ä–∞—Ñ–µ –≤—ã–∑–æ–≤–æ–≤ —Å–µ—Ä–≤–∏—Å–æ–≤\n",
        "import json\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.nn import APPNP\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, ndcg_score\n",
        "\n",
        "# ==================== DAGNN (–≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π) ====================\n",
        "class DAGNN(nn.Module):\n",
        "    def __init__(self, in_channels: int, K: int):\n",
        "        super().__init__()\n",
        "        self.propagation = APPNP(K=K, alpha=0)\n",
        "        self.att = nn.Parameter(torch.Tensor(K + 1))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.propagation.reset_parameters()\n",
        "        nn.init.zeros_(self.att)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        xs = [x]\n",
        "        edge_weight = torch.ones(edge_index.size(1), dtype=torch.float32, device=edge_index.device)\n",
        "        for _ in range(self.propagation.K):\n",
        "            x = self.propagation.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
        "            xs.append(x)\n",
        "        out = torch.stack(xs, dim=-1)\n",
        "        out = (out * self.att.view(1, 1, -1)).sum(dim=-1)\n",
        "        return out\n",
        "\n",
        "# ==================== DAGNN Recommender ====================\n",
        "class DAGNNRecommender(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, K=10):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(in_channels, hidden_channels)\n",
        "        self.dagnn = DAGNN(hidden_channels, K)\n",
        "        self.lin2 = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.dagnn(x, edge_index)\n",
        "        x = self.lin2(x)\n",
        "        return x\n",
        "\n",
        "# ==================== GAT ====================\n",
        "class GATRecommender(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads=2):\n",
        "        super().__init__()\n",
        "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads)\n",
        "        self.gat2 = GATConv(hidden_channels * heads, out_channels, heads=1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.elu(self.gat1(x, edge_index))\n",
        "        x = self.gat2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ==================== GCN ====================\n",
        "class GCNRecommender(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# ==================== –£—Ç–∏–ª–∏—Ç–∞ ====================\n",
        "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏ —Å nDCG\n",
        "def evaluate_model_with_ndcg(preds, true_labels, proba_preds=None, name=\"Model\", label_binarizer=None):\n",
        "    acc = accuracy_score(true_labels, preds)\n",
        "    f1 = f1_score(true_labels, preds, average='macro')\n",
        "    precision = precision_score(true_labels, preds, average='macro')\n",
        "    recall = recall_score(true_labels, preds, average='macro')\n",
        "\n",
        "    # if proba_preds is not None and label_binarizer is not None:\n",
        "    #     true_binarized = label_binarizer.transform(true_labels)\n",
        "    #     ndcg = ndcg_score(true_binarized, proba_preds)\n",
        "    # else:\n",
        "    #     ndcg = None\n",
        "    print(f\"\\nüìä {name} Metrics\")\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"F1-score:  {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    # if ndcg is not None:\n",
        "    #     print(f\"nDCG:      {ndcg:.4f}\")\n",
        "    # else:\n",
        "    #     print(\"nDCG:      Not available\")\n",
        "    if proba_preds is not None:\n",
        "        try:\n",
        "            n_classes = proba_preds.shape[1]\n",
        "            lb = LabelBinarizer()\n",
        "            lb.fit(range(n_classes))\n",
        "            true_bin = lb.transform(true_labels)\n",
        "\n",
        "            # –ï—Å–ª–∏ true_bin –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π, –ø—Ä–µ–≤—Ä–∞—Ç–∏–º –µ–≥–æ –≤ one-hot –≤—Ä—É—á–Ω—É—é\n",
        "            if true_bin.ndim == 1:\n",
        "                true_bin = np.eye(n_classes)[true_labels]\n",
        "\n",
        "            ndcg = ndcg_score(true_bin, proba_preds)\n",
        "            print(f\"nDCG:      {ndcg:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"nDCG:      ‚ùå Error calculating nDCG: {e}\")\n",
        "    else:\n",
        "        print(\"nDCG:      Not available (no probabilities)\")\n",
        "\n",
        "# ==================== –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥ ====================\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –∏–∑ JSON\n",
        "with open(\"compositionsDAG.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "dag = nx.DiGraph()\n",
        "id_to_mid = {}\n",
        "\n",
        "for composition in data:\n",
        "    for node in composition[\"nodes\"]:\n",
        "        if \"mid\" in node:\n",
        "            id_to_mid[str(node[\"id\"])] = f\"service_{node['mid']}\"\n",
        "        else:\n",
        "            id_to_mid[str(node[\"id\"])] = f\"table_{node['id']}\"\n",
        "\n",
        "    for link in composition[\"links\"]:\n",
        "        source = str(link[\"source\"])\n",
        "        target = str(link[\"target\"])\n",
        "        src_node = id_to_mid[source]\n",
        "        tgt_node = id_to_mid[target]\n",
        "        dag.add_node(src_node, type='service' if src_node.startswith(\"service\") else 'table')\n",
        "        dag.add_node(tgt_node, type='service' if tgt_node.startswith(\"service\") else 'table')\n",
        "        dag.add_edge(src_node, tgt_node)\n",
        "\n",
        "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—É—Ç–µ–π –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
        "# –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Ç–∏ –≤ DAG –¥–ª–∏–Ω–æ–π –æ—Ç 2 –¥–æ N (–∫–æ–Ω—Ç–µ–∫—Å—Ç—ã)\n",
        "paths = []\n",
        "\n",
        "for start_node in dag.nodes:\n",
        "    if dag.out_degree(start_node) > 0:\n",
        "        for path in nx.dfs_edges(dag, source=start_node):\n",
        "            full_path = [path[0], path[1]]\n",
        "            while dag.out_degree(full_path[-1]) > 0:\n",
        "                next_nodes = list(dag.successors(full_path[-1]))\n",
        "                if not next_nodes:\n",
        "                    break\n",
        "                full_path.append(next_nodes[0])  # –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å: —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –≤—Å–µ –≤–µ—Ç–∫–∏\n",
        "            if len(full_path) > 1:\n",
        "                paths.append(full_path)\n",
        "\n",
        "# –°—Ç—Ä–æ–∏–º –≤—ã–±–æ—Ä–∫—É: (–∫–æ–Ω—Ç–µ–∫—Å—Ç) -> (—Å–ª–µ–¥—É—é—â–∏–π mid)\n",
        "X_raw = []\n",
        "y_raw = []\n",
        "\n",
        "for path in paths:\n",
        "    for i in range(1, len(path) - 1):\n",
        "        context = tuple(path[:i])  # –∫–æ–Ω—Ç–µ–∫—Å—Ç: –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —à–∞–≥–∏\n",
        "        next_step = path[i]\n",
        "        if next_step.startswith(\"service\"):\n",
        "            X_raw.append(context)\n",
        "            y_raw.append(next_step)\n",
        "\n",
        "# –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è\n",
        "mlb = MultiLabelBinarizer()\n",
        "X = mlb.fit_transform(X_raw)\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_raw)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –±–∏–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è nDCG (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É)\n",
        "lb = LabelBinarizer()\n",
        "lb.fit(y_test)\n",
        "\n",
        "# ==================== Model 1: Random Forest ====================\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_preds = rf.predict(X_test)\n",
        "rf_proba = rf.predict_proba(X_test)\n",
        "# evaluate_model(rf_preds, y_test, name=\"Random Forest\")\n",
        "evaluate_model_with_ndcg(rf_preds, y_test, proba_preds=rf_proba, name=\"Random Forest\", label_binarizer=lb)\n",
        "\n",
        "\n",
        "# ==================== Model 2: Popularity ====================\n",
        "counter = Counter(y_raw)\n",
        "top_label = counter.most_common(1)[0][0]\n",
        "pop_preds = [le.transform([top_label])[0]] * len(y_test)\n",
        "# –°–∏–º—É–ª–∏—Ä—É–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: 1 –¥–ª—è —Å–∞–º–æ–≥–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞, 0 –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö\n",
        "pop_proba = np.zeros_like(rf_proba)\n",
        "top_label_index = le.transform([top_label])[0]\n",
        "pop_proba[:, top_label_index] = 1\n",
        "evaluate_model_with_ndcg(pop_preds, y_test, proba_preds=pop_proba, name=\"Popularity-Based\", label_binarizer=lb)\n",
        "\n",
        "# ==================== PyG –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ ====================\n",
        "node_list = list(dag.nodes)\n",
        "node_encoder = LabelEncoder()\n",
        "node_ids = node_encoder.fit_transform(node_list)\n",
        "node_map = {node: idx for node, idx in zip(node_list, node_ids)}\n",
        "\n",
        "edge_index = torch.tensor([[node_map[u], node_map[v]] for u, v in dag.edges], dtype=torch.long).t()\n",
        "features = [[1, 0] if dag.nodes[n]['type'] == 'service' else [0, 1] for n in node_list]\n",
        "x = torch.tensor(features, dtype=torch.float)\n",
        "data_pyg = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "contexts = torch.tensor([node_map[context[-1]] for context in X_raw], dtype=torch.long)\n",
        "targets = torch.tensor([node_map[y] for y in y_raw], dtype=torch.long)\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "lb.fit(targets.numpy())  # gcn_true = targets.numpy()\n",
        "\n",
        "# ==================== Model 3: GCN ====================\n",
        "gcn = GCNRecommender(in_channels=2, hidden_channels=16, out_channels=len(node_list))\n",
        "opt = torch.optim.Adam(gcn.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(100):\n",
        "    # gcn.train()\n",
        "    # opt.zero_grad()\n",
        "    # out = gcn(data_pyg)[contexts]\n",
        "    # loss = F.cross_entropy(out, targets)\n",
        "    # loss.backward()\n",
        "    # opt.step()\n",
        "\n",
        "    gcn.train()\n",
        "    opt.zero_grad()\n",
        "    out = gcn(data_pyg)[contexts]\n",
        "    loss = torch.nn.functional.cross_entropy(out, targets)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "gcn.eval()\n",
        "with torch.no_grad():\n",
        "    gcn_output = gcn(data_pyg)[contexts]\n",
        "    gcn_preds = gcn_output.argmax(dim=1).numpy()\n",
        "    gcn_proba = torch.nn.functional.softmax(gcn_output, dim=1).numpy()\n",
        "    gcn_true = targets.numpy()\n",
        "\n",
        "    evaluate_model_with_ndcg(gcn_preds, gcn_true, proba_preds=gcn_proba, name=\"GCN\", label_binarizer=lb)\n",
        "\n",
        "# ==================== Model 4: DAGNN ====================\n",
        "dagnn = DAGNNRecommender(in_channels=2, hidden_channels=16, out_channels=len(node_list))\n",
        "opt = torch.optim.Adam(dagnn.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(100):\n",
        "    dagnn.train()\n",
        "    opt.zero_grad()\n",
        "    out = dagnn(data_pyg.x, data_pyg.edge_index)[contexts]\n",
        "    loss = F.cross_entropy(out, targets)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "dagnn.eval()\n",
        "with torch.no_grad():\n",
        "    dagnn_output = dagnn(data_pyg.x, data_pyg.edge_index)[contexts]\n",
        "    dagnn_preds = dagnn_output.argmax(dim=1).numpy()\n",
        "    dagnn_proba = torch.nn.functional.softmax(dagnn_output, dim=1).numpy()\n",
        "    evaluate_model_with_ndcg(dagnn_preds, gcn_true, proba_preds=dagnn_proba, name=\"DAGNN\", label_binarizer=lb)\n",
        "\n",
        "# ==================== Model 5: GAT ====================\n",
        "gat = GATRecommender(in_channels=2, hidden_channels=16, out_channels=len(node_list), heads=2)\n",
        "opt = torch.optim.Adam(gat.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(100):\n",
        "    gat.train()\n",
        "    opt.zero_grad()\n",
        "    out = gat(data_pyg)[contexts]\n",
        "    loss = F.cross_entropy(out, targets)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "gat.eval()\n",
        "with torch.no_grad():\n",
        "    gat_output = gat(data_pyg)[contexts]\n",
        "    gat_preds = gat_output.argmax(dim=1).numpy()\n",
        "    gat_proba = torch.nn.functional.softmax(gat_output, dim=1).numpy()\n",
        "    evaluate_model_with_ndcg(gat_preds, gcn_true, proba_preds=gat_proba, name=\"GAT\", label_binarizer=lb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCgYVrP7MqJb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}