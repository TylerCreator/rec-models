# SR-GNN: полный рабочий цикл

Этот документ описывает, как в скрипте `sequence recomendation/directed_dag_models.py` реализована и запускается модель **Session-based Recommendation with Graph Neural Networks (SR-GNN)** после адаптации под графы из реальных композиций. Ниже разбираются все шаги — от подготовки датасета до получения итоговых метрик.

---

## 1. Подготовка данных

### 1.1. Загрузка и парсинг DAG-композиций
1. Скрипт читает файл `compositionsDAG.json` и восстанавливает исходные направленные графы (`load_dag_from_json`).
2. Дополнительно извлекаются все реальные пути из композиций (`extract_paths_from_compositions`) — они понадобятся, чтобы построить обучающие пары «контекст → следующий сервис».

### 1.2. Формирование обучающих примеров
1. Функция `create_training_pairs` разбивает каждый путь на:
   - контекст (последовательность узлов до текущего сервиса);
   - таргет — сервис, который нужно предсказать.
2. Далее вызывается `split_data`, чтобы разделить пары на train/test с учётом ID композиции. В результате получаем:
   - `ctx_train`, `ctx_test` — списки контекстов;
   - `y_train`, `y_test` — списки целевых сервисов;
   - `comp_train_idx`, `comp_test_idx` — ID композиций для каждого примера.

### 1.3. Построение глобального графа
1. Берём только те пути, что относятся к композициям из train-части (`train_paths_only`).
2. Строим глобальный направленный граф с весами переходов (`build_graph`). Все узлы кодируются как строки `service_*` и `table_*`.
3. Функция `prepare_pyg` превращает глобальный граф в формат PyTorch Geometric (`Data`), создавая:
   - `node_map` — сопоставление имени узла и его индекса;
   - двухмерный признак типа узла (`service/table`) для всех моделей (SR-GNN он нужен только ради единого маппинга).

### 1.4. Контексты для SR-GNN
SR-GNN не разворачивает графы в сессии, поэтому мы просто преобразуем каждый контекст в список индексов узлов глобального графа:

```python
train_samples = build_srgnn_samples_from_contexts(ctx_train, train_target_indices, node_map)
test_samples = build_srgnn_samples_from_contexts(ctx_test, test_target_indices, node_map)
```

Каждый элемент списка — пара `(node_indices, target_class)`:
- `node_indices`: последовательность глобальных индексов (без +1 padding, так как граф общая embedding-матрица уже содержит padding в позиции 0).
- `target_class`: индекс сервиса (через `service_map`).

### 1.5. Глобальная матрица смежности SR-GNN
Чтобы SR-GNN работала в тех же условиях, что и остальные модели, мы строим **единственный глобальный adjacency**:

```python
global_adj = build_global_srgnn_adj(data_pyg.edge_index, num_nodes)
```

Она хранит нормализованные входящие и исходящие веса (`[A_in, A_out]`), как требуется в оригинальной статье SR-GNN.

---

## 2. Архитектура SR-GNN

SR-GNN состоит из трёх логических блоков, повторяющих оригинальный `SessionGraph`, но адаптированных для глобального графа:

### 2.1. Эмбеддинги узлов
- Матрица `Embedding(num_nodes + 1, hidden)` (первый индекс зарезервирован под padding, поэтому реальные узлы сдвинуты на +1).
- Глобальные индексы `node_map` гарантируют, что один и тот же узел (например, `service_123`) всегда попадает в одну строку embedding-матрицы, независимо от композиции.
- Обновление весов происходит только за счёт loss внутри SR-GNN; никакие внешние признаки сюда не добавляются.

### 2.2. GNN-пропагатор `SRGNNGNN`

Это специализированная GRU-ячейка с раздельными потоками «входящих» и «исходящих» сообщений:

1. **Подготовка входов**  
   Матрица смежности `A` имеет форму `(N, 2N)` — первые `N` столбцов отвечают за нормализованные входящие связи, вторые `N` — за исходящие.  
   ```
   input_in  = A[:, :, :N]  · linear_edge_in(hidden)  + b_iah
   input_out = A[:, :, N:]  · linear_edge_out(hidden) + b_oah
   ```
2. **Объединение**  
   Вектор `inputs = concat(input_in, input_out)` подаётся в стандартные GRU-гейты (`w_ih`, `w_hh`, `b_*`). На выходе получаем обновлённое состояние `hy = newgate + inputgate * (hidden - newgate)`.
3. **Количество шагов**  
   Параметр `--sr-steps` задаёт число итераций пропагации (по умолчанию 1, но можно увеличивать, чтобы захватывать более дальние связи).

Таким образом, узлы получают информацию как от предков, так и от потомков, сохраняя чувствительность к направленности графа.

### 2.3. Attention readout + head

После пропагации мы должны извлечь представление конкретного контекста (последовательности узлов):

1. **Выбор последовательности**  
   По каждой сессии берём скрытые состояния `seq_hidden = hidden[alias_indices]`, где `alias_indices` — прямое отображение контекста в глобальные индексы.
2. **Последний элемент**  
   `ht = seq_hidden[:, -1]` — аналог «последнего клика».
3. **Вычисление attention**  
   ```
   q1 = linear_one(ht)   # запрос
   q2 = linear_two(seq_hidden)  # ключи
   alpha = linear_three(sigmoid(q1 + q2))
   session_vec = Σ alpha * seq_hidden
   ```
4. **Hybrid-преференция**  
   Если флаг `--sr-nonhybrid` не задан, объединяем session_vec и ht через `linear_transform([session_vec, ht])`. Это позволяет учитывать как глобальный контекст, так и «последний шаг».
5. **Скоринг по сервисам**  
   Финальный вектор умножается на матрицу эмбеддингов только сервисных узлов (`service_indices`). Это сокращает размер logits и полностью синхронизирует SR-GNN с задачей предсказания следующего сервиса.

Итоговая архитектура остаётся строго идентичной оригинальной SR-GNN, но работает на едином глобальном графе, поэтому результаты можно напрямую сравнивать с другими GNN-моделями.

---

## 3. Обучение и валидация

### 3.1. Функция `train_srgnn_global_graph`

Основной цикл:

```python
items_tensor = (torch.arange(num_nodes) + 1).unsqueeze(0)
global_adj = build_global_srgnn_adj(...)
hidden = model(items_tensor, global_adj)

for seq_indices, target in train_samples:
    alias = torch.tensor([seq_indices])
    mask = torch.ones(...)
    seq_hidden = model.gather_sequence(hidden, alias)
    scores = model.compute_scores(seq_hidden, mask, service_indices)
    loss = CrossEntropy(scores, target)
```

- **Важно**: скрытое состояние `hidden` вычисляем один раз на глобальном графе и переиспользуем для всех контекстов.
- **Loss**: стандартный `CrossEntropyLoss`.
- **Оптимизатор**: `Adam`, lr задаётся флагом `--sr-lr`.
- **Логи**: каждые 10 эпох выводим средний loss.

При тестировании делаем то же самое, но просто накапливаем `argmax`, `softmax` и таргеты, после чего считаем метрики (accuracy, macro-F1, precision/recall и NDCG@min(10, #classes)`).

### 3.2. Метрики
Метрики считаются через `compute_metrics` для всех моделей одинаково. Для SR-GNN на текущем датасете мы получаем (100 эпох):

```
accuracy ≈ 0.538
f1       ≈ 0.262
ndcg     ≈ 0.777
```

Это сравнимо с GRU4Rec (0.534 / 0.224 / 0.767) и выше, чем у остальных GNN-бейзлайнов (~0.52 acc). Главное — теперь SR-GNN учится на тех же данных, что и конкуренты, без утечек.

---

## 4. Как запустить

```bash
cd /Users/kmc/projects/rec-models
python3 "sequence recomendation/directed_dag_models.py" \
    --data "sequence recomendation/compositionsDAG.json" \
    --epochs 100 \
    --sr-hidden 128 \
    --sr-steps 1 \
    --sr-lr 5e-4
```

- При желании можно настроить `--sr-hidden`, `--sr-steps` (число propagation-итераций) и `--sr-nonhybrid` (отключить гибридный скоринг).
- Все результаты печатаются в конце как таблица по моделям.

---

## 5. Ключевые отличия от оригинального SR-GNN

1. **Глобальный граф вместо сессионных подграфов.** Оригинальный код строит свою матрицу A отдельно для каждой сессии; мы строим один граф, чтобы условия совпадали с другими моделями.
2. **Ограничение кандидатов сервисами.** Благодаря `service_indices` скорим только по реально возможным целям.
3. **Контексты берутся из DAG-путей**, но нисколько не изменяются, кроме отображения в индексы глобального графа.

---

## 6. Выводы и дальнейшие шаги

- **Сравнение с простой популярностью.** Бейзлайн “Popularity” всегда рекомендует самый частотный сервис и на данных композиций даёт `accuracy ≈ 0.48`, `f1 ≈ 0.054`, `ndcg ≈ 0.61`. Даже базовая SR-GNN (на глобальном графе и без утечек) выдаёт `accuracy ≈ 0.54`, `f1 ≈ 0.26`, `ndcg ≈ 0.78`, то есть заметно превосходит тривиальные подсказки и умеет учитывать структуру DAG.
- Текущая реализация SR-GNN честно сопоставима с остальными моделями: все используют только граф, построенный по train-композициям.
- Модель показывает заметный прирост F1/NDCG по сравнению с классическими GNN-бейзлайнами.
- Возможные улучшения:
  - добавить регуляризацию по владельцам (owner embeddings);
  - варьировать `sr_steps` и `hidden`;
  - экспериментировать с частичным fine-tuning на per-composition DAG (если нужно «локальное» адаптирование).

Для всех деталей смотрите реализацию в `directed_dag_models.py` (разделы `SRGNNGNN`, `SRGNNRecommender`, `build_global_srgnn_adj`, `train_srgnn_global_graph`).

---

**Автор**: Автоматизированная адаптация SR-GNN в рамках репозитория `rec-models`  
**Последнее обновление**: 24 ноября 2025

