# üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ DAGNN: –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
1. [–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö](#1-–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞-–¥–∞–Ω–Ω—ã—Ö)
2. [–í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏](#2-–≤—Ö–æ–¥–Ω—ã–µ-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã-–º–æ–¥–µ–ª–∏)
3. [Encoder Block](#3-encoder-block)
4. [Residual Connection](#4-residual-connection)
5. [DAGNN Propagation](#5-dagnn-propagation)
6. [Classifier](#6-classifier)
7. [–ü–æ–ª–Ω—ã–π Forward Pass](#7-–ø–æ–ª–Ω—ã–π-forward-pass)

---

## 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

### –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

**–§–∞–π–ª:** `compositionsDAG.json`
```json
{
  "id": "comp_001",
  "composition": {
    "nodes": [
      {"id": "n1", "service": "table_1002132"},
      {"id": "n2", "service": "service_308"},
      {"id": "n3", "service": "service_309"}
    ],
    "links": [
      {"source": "n1", "target": "n2"},
      {"source": "n2", "target": "n3"}
    ]
  }
}
```

**–ß—Ç–æ –∏–∑–≤–ª–µ–∫–∞–µ–º:**
- 943 –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ ‚Üí 106 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—É—Ç–µ–π
- –ü—Ä–∏–º–µ—Ä –ø—É—Ç–∏: `['table_1002132', 'service_308', 'service_309']`

---

### –®–∞–≥ 1.1: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—É—Ç–µ–π

**–§—É–Ω–∫—Ü–∏—è:** `build_graph_from_real_paths(paths)`

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
```python
path_graph = nx.DiGraph()  # –°–æ–∑–¥–∞–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≥—Ä–∞—Ñ

for path in paths:  # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏
    for i in range(len(path) - 1):
        source = path[i]      # –ù–∞–ø—Ä–∏–º–µ—Ä: 'table_1002132'
        target = path[i + 1]  # –ù–∞–ø—Ä–∏–º–µ—Ä: 'service_308'
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —É–∑–ª–∞
        source_type = 'service' if source.startswith('service') else 'table'
        target_type = 'service' if target.startswith('service') else 'table'
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –≥—Ä–∞—Ñ
        path_graph.add_node(source, type=source_type)
        path_graph.add_node(target, type=target_type)
        path_graph.add_edge(source, target)
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```
–ì—Ä–∞—Ñ:
  - 50 —É–∑–ª–æ–≤ (15 —Å–µ—Ä–≤–∏—Å–æ–≤ + 35 —Ç–∞–±–ª–∏—Ü)
  - 97 –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ä–µ–±–µ—Ä
  - –°–≤—è–∑–∏: table ‚Üí service, service ‚Üí service
```

**–ó–∞—á–µ–º –Ω—É–∂–µ–Ω –≥—Ä–∞—Ñ:**
- –ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –º–µ–∂–¥—É —É–∑–ª–∞–º–∏
- DAGNN –±—É–¥–µ—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —ç—Ç–∏–º —Å–≤—è–∑—è–º
- –ì—Ä–∞—Ñ –∫–æ–¥–∏—Ä—É–µ—Ç, –∫–∞–∫–∏–µ —É–∑–ª—ã –≤–ª–∏—è—é—Ç –¥—Ä—É–≥ –Ω–∞ –¥—Ä—É–≥–∞

---

### –®–∞–≥ 1.2: –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤

**–§—É–Ω–∫—Ü–∏—è:** `create_training_data(paths)`

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
```python
X_raw = []  # –ö–æ–Ω—Ç–µ–∫—Å—Ç—ã
y_raw = []  # –¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

for path in paths:
    # path = ['table_1002132', 'service_308', 'service_309']
    
    for i in range(1, len(path)):
        context = tuple(path[:i])  # ('table_1002132',) –∏–ª–∏ ('table_1002132', 'service_308')
        next_step = path[i]         # 'service_308' –∏–ª–∏ 'service_309'
        
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ—Ö–æ–¥—ã –Ω–∞ —Å–µ—Ä–≤–∏—Å—ã (–æ–Ω–∏ - —Ü–µ–ª–µ–≤—ã–µ –∫–ª–∞—Å—Å—ã)
        if next_step.startswith("service"):
            X_raw.append(context)
            y_raw.append(next_step)
```

**–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:**

| ‚Ññ | –ö–æ–Ω—Ç–µ–∫—Å—Ç (X_raw) | –¶–µ–ª–µ–≤–æ–π —Å–µ—Ä–≤–∏—Å (y_raw) | –ü–æ—è—Å–Ω–µ–Ω–∏–µ |
|---|------------------|------------------------|-----------|
| 0 | `('table_1002132',)` | `'service_308'` | –ü–æ—Å–ª–µ —Ç–∞–±–ª–∏—Ü—ã ‚Üí –ø–µ—Ä–≤—ã–π —Å–µ—Ä–≤–∏—Å |
| 1 | `('table_1002132', 'service_308')` | `'service_309'` | –ü–æ—Å–ª–µ table+service ‚Üí —Å–ª–µ–¥—É—é—â–∏–π —Å–µ—Ä–≤–∏—Å |

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- 125 –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
- X_raw: —Å–ø–∏—Å–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ (–ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª–∏–Ω—ã)
- y_raw: –Ω–∞–∑–≤–∞–Ω–∏—è —Ü–µ–ª–µ–≤—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤

**–ó–∞—á–µ–º:**
- –ó–∞–¥–∞—á–∞: –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Å–µ—Ä–≤–∏—Å
- –≠—Ç–æ supervised learning - –Ω—É–∂–Ω—ã –ø–∞—Ä—ã (–≤—Ö–æ–¥, –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç)

---

### –®–∞–≥ 1.3: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è PyTorch Geometric

**–§—É–Ω–∫—Ü–∏—è:** `prepare_pytorch_geometric_data(dag, X_raw, y_raw, paths)`

#### 1.3.1: –ú–∞–ø–ø–∏–Ω–≥ —É–∑–ª–æ–≤ ‚Üí –∏–Ω–¥–µ–∫—Å—ã

```python
node_list = list(path_graph.nodes)
# ['table_1002132', 'table_1002133', ..., 'service_308', 'service_309', ...]

node_encoder = LabelEncoder()
node_ids = node_encoder.fit_transform(node_list)
# [0, 1, 2, ..., 48, 49]

node_map = {node: idx for node, idx in zip(node_list, node_ids)}
# {
#   'table_1002132': 0,
#   'table_1002133': 1,
#   ...
#   'service_308': 35,
#   'service_309': 36,
#   ...
# }
```

**–ó–∞—á–µ–º –Ω—É–∂–µ–Ω node_map:**
- –ù–µ–π—Ä–æ—Å–µ—Ç–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Å —á–∏—Å–ª–∞–º–∏, –Ω–µ —Å–æ —Å—Ç—Ä–æ–∫–∞–º–∏
- –ö–∞–∂–¥–æ–º—É —É–∑–ª—É –Ω–∞–∑–Ω–∞—á–∞–µ—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å 0-49
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è edge_index –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤

#### 1.3.2: –°–æ–∑–¥–∞–Ω–∏–µ edge_index

```python
edge_index = torch.tensor(
    [[node_map[u], node_map[v]] for u, v in path_graph.edges],
    dtype=torch.long
).t()

# –ü—Ä–∏–º–µ—Ä:
# path_graph.edges: [('table_1002132', 'service_308'), ('service_308', 'service_309'), ...]
# 
# edge_index –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:
# tensor([[0, 35, 36, ...],    ‚Üê –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (source nodes)
#         [35, 36, 37, ...]])  ‚Üê –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è (target nodes)
```

**–§–æ—Ä–º–∞—Ç edge_index: [2, num_edges]**
```
edge_index[0] = [0,  35, 36, ...]  ‚Üê –∏–Ω–¥–µ–∫—Å—ã —É–∑–ª–æ–≤-–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
edge_index[1] = [35, 36, 37, ...]  ‚Üê –∏–Ω–¥–µ–∫—Å—ã —É–∑–ª–æ–≤-–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π

–û–∑–Ω–∞—á–∞–µ—Ç —Ä–µ–±—Ä–∞:
  0 ‚Üí 35  (table_1002132 ‚Üí service_308)
  35 ‚Üí 36 (service_308 ‚Üí service_309)
  36 ‚Üí 37 (service_309 ‚Üí service_312)
  ...
```

**–ó–∞—á–µ–º –Ω—É–∂–µ–Ω edge_index:**
- **–ì–ª–∞–≤–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è GNN!**
- –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≥—Ä–∞—Ñ–∞
- DAGNN –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –µ–≥–æ –¥–ª—è propagation (—Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏)
- –ì–æ–≤–æ—Ä–∏—Ç: "–∫—Ç–æ —Å –∫–µ–º —Å–≤—è–∑–∞–Ω –∏ –≤ –∫–∞–∫–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏"

#### 1.3.3: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —É–∑–ª–æ–≤ (x)

```python
features = [
    [1, 0] if path_graph.nodes[n]['type'] == 'service' 
    else [0, 1] 
    for n in node_list
]

x = torch.tensor(features, dtype=torch.float)
# –†–µ–∑—É–ª—å—Ç–∞—Ç: tensor([
#   [0, 1],  ‚Üê table_1002132
#   [0, 1],  ‚Üê table_1002133
#   ...
#   [1, 0],  ‚Üê service_308
#   [1, 0],  ‚Üê service_309
#   ...
# ])
# –†–∞–∑–º–µ—Ä: [50, 2]
```

**–ü—Ä–∏–∑–Ω–∞–∫–∏ —É–∑–ª–æ–≤:**
- `[1, 0]` = —Å–µ—Ä–≤–∏—Å (is_service=1, is_table=0)
- `[0, 1]` = —Ç–∞–±–ª–∏—Ü–∞ (is_service=0, is_table=1)

**–ó–∞—á–µ–º —Ç–æ–ª—å–∫–æ 2 –ø—Ä–∏–∑–Ω–∞–∫–∞:**
- –ù–∞ –º–∞–ª–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –ª—É—á—à–µ
- –ë–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Üí –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
- DAGNN —Å–∞–º –∏–∑–≤–ª–µ—á–µ—Ç —Å–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —á–µ—Ä–µ–∑ propagation

#### 1.3.4: –°–æ–∑–¥–∞–Ω–∏–µ PyTorch Geometric Data

```python
data_pyg = Data(x=x, edge_index=edge_index)

# data_pyg —Å–æ–¥–µ—Ä–∂–∏—Ç:
#   - x: [50, 2] - –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤—Å–µ—Ö 50 —É–∑–ª–æ–≤
#   - edge_index: [2, 97] - 97 –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ä–µ–±–µ—Ä
```

**–ó–∞—á–µ–º Data object:**
- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç PyTorch Geometric
- –£–¥–æ–±–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –≤ GNN –º–æ–¥–µ–ª–∏
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–µ–π

#### 1.3.5: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –∏ —Ü–µ–ª–µ–π

```python
# –ö–æ–Ω—Ç–µ–∫—Å—Ç—ã - –∏–Ω–¥–µ–∫—Å—ã –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —É–∑–ª–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞—Ö
contexts = torch.tensor([node_map[context[-1]] for context in X_raw], dtype=torch.long)
# contexts = [0, 35, 36, ...]  - –∏–Ω–¥–µ–∫—Å—ã —É–∑–ª–æ–≤ –≤ node_map
# –†–∞–∑–º–µ—Ä: [125]

# –¶–µ–ª–µ–≤—ã–µ –∫–ª–∞—Å—Å—ã - —Å–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ –¢–û–õ–¨–ö–û –¥–ª—è —Å–µ—Ä–≤–∏—Å–æ–≤
unique_services = sorted(set(y_raw))
# ['service_306', 'service_307', ..., 'service_397'] - 15 —Å–µ—Ä–≤–∏—Å–æ–≤

service_map = {service: idx for idx, service in enumerate(unique_services)}
# {
#   'service_306': 0,
#   'service_307': 1,
#   'service_308': 2,
#   ...
#   'service_397': 14
# }

targets = torch.tensor([service_map[y] for y in y_raw], dtype=torch.long)
# targets = [2, 3, 2, ...]  - –∏–Ω–¥–µ–∫—Å—ã –∫–ª–∞—Å—Å–æ–≤ –≤ service_map
# –†–∞–∑–º–µ—Ä: [125]
```

**–í–∞–∂–Ω–æ:**
- `contexts` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `node_map` (–∏–Ω–¥–µ–∫—Å—ã 0-49 –¥–ª—è –≤—Å–µ—Ö —É–∑–ª–æ–≤)
- `targets` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `service_map` (–∏–Ω–¥–µ–∫—Å—ã 0-14 –¥–ª—è —Å–µ—Ä–≤–∏—Å–æ–≤)
- –≠—Ç–æ –†–ê–ó–ù–´–ï –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –∏–Ω–¥–µ–∫—Å–æ–≤!

**–ó–∞—á–µ–º –¥–≤–∞ –º–∞–ø–ø–∏–Ω–≥–∞:**
- `node_map`: –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≥—Ä–∞—Ñ–æ–º (–≤—Å–µ 50 —É–∑–ª–æ–≤)
- `service_map`: –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (—Ç–æ–ª—å–∫–æ 15 —Ü–µ–ª–µ–≤—ã—Ö –∫–ª–∞—Å—Å–æ–≤)

---

### –ò—Ç–æ–≥ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö

**–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:**

1. **data_pyg** - –≥—Ä–∞—Ñ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏:
   - `x`: [50, 2] - –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤—Å–µ—Ö —É–∑–ª–æ–≤
   - `edge_index`: [2, 97] - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≥—Ä–∞—Ñ–∞

2. **contexts** - [125] - –∏–Ω–¥–µ–∫—Å—ã –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —É–∑–ª–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –≤ node_map

3. **targets** - [125] - –∏–Ω–¥–µ–∫—Å—ã —Ü–µ–ª–µ–≤—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –≤ service_map

4. **node_map** - 50 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (–≤—Å–µ —É–∑–ª—ã ‚Üí –∏–Ω–¥–µ–∫—Å—ã 0-49)

5. **service_map** - 15 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (—Å–µ—Ä–≤–∏—Å—ã ‚Üí –∏–Ω–¥–µ–∫—Å—ã 0-14)

**Split –Ω–∞ train/test:**
```python
# 87 train / 38 test
contexts_train, contexts_test, targets_train, targets_test = train_test_split(
    contexts, targets, test_size=0.3, random_state=42
)
```

---

## 2. –í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ DAGNNRecommender

```python
class DAGNNRecommender(nn.Module):
    def __init__(self, 
                 in_channels: int,      # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —É–∑–ª–æ–≤
                 hidden_channels: int,  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤
                 out_channels: int,     # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                 K: int = 10,           # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ propagation hops
                 dropout: float = 0.4   # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å dropout
    ):
```

### –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏:

```python
model = DAGNNRecommender(
    in_channels=2,        # 2 –ø—Ä–∏–∑–Ω–∞–∫–∞ —É–∑–ª–∞: [is_service, is_table]
    hidden_channels=64,   # –†–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —É–∑–ª–æ–≤
    out_channels=15,      # 15 –∫–ª–∞—Å—Å–æ–≤ (—Å–µ—Ä–≤–∏—Å–æ–≤) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    K=10,                 # 10 hops —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    dropout=0.4           # 40% dropout –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
)
```

### –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:

**in_channels = 2:**
- –ö–∞–∂–¥—ã–π —É–∑–µ–ª –æ–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è 2 –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏: `[is_service, is_table]`
- –ü—Ä–æ—Å—Ç—ã–µ –±–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –ª—É—á—à–µ –Ω–∞ –º–∞–ª–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
- –í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –¥–æ–ª–∂–µ–Ω –ø—Ä–∏–Ω—è—Ç—å —ç—Ç–∏ 2 –ø—Ä–∏–∑–Ω–∞–∫–∞

**hidden_channels = 64:**
- –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π (—ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)
- –í—Å–µ —É–∑–ª—ã –±—É–¥—É—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤–µ–∫—Ç–æ—Ä–∞–º–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 64
- –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤, –Ω–æ –Ω–µ –∏–∑–±—ã—Ç–æ—á–Ω–æ

**out_channels = 15:**
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤ = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–µ–ª–µ–≤—ã—Ö –∫–ª–∞—Å—Å–æ–≤
- 15 —Å–µ—Ä–≤–∏—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å
- –ö–∞–∂–¥—ã–π –Ω–µ–π—Ä–æ–Ω = –æ—Ü–µ–Ω–∫–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞

**K = 10:**
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è (propagation hops)
- –ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞ —Å–æ—Å–µ–¥–µ–π
- 10 hops –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–æ–π—Ç–∏ –¥–∞–ª–µ–∫–æ –ø–æ –≥—Ä–∞—Ñ—É

**dropout = 0.4:**
- –ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —Å–ª—É—á–∞–π–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º 40% –Ω–µ–π—Ä–æ–Ω–æ–≤
- –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
- –£–ª—É—á—à–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—é

---

### –î–∞–Ω–Ω—ã–µ –Ω–∞ –≤—Ö–æ–¥–µ forward pass

```python
def forward(self, x, edge_index, training=True):
    # x: [50, 2] - –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤—Å–µ—Ö —É–∑–ª–æ–≤ –≥—Ä–∞—Ñ–∞
    # edge_index: [2, 97] - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≥—Ä–∞—Ñ–∞
    # training: True/False - —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è/inference
```

**x: Node features [50, 2]**
```python
x = tensor([
    [0, 1],  # —É–∑–µ–ª 0 (table_1002132): is_table
    [0, 1],  # —É–∑–µ–ª 1 (table_1002133): is_table
    ...
    [1, 0],  # —É–∑–µ–ª 35 (service_308): is_service
    [1, 0],  # —É–∑–µ–ª 36 (service_309): is_service
    ...
])
```

**edge_index: Graph structure [2, 97]**
```python
edge_index = tensor([
    [0,  35, 36, 1,  35, ...],  # –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    [35, 36, 37, 35, 40, ...]   # –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
])

# –û–∑–Ω–∞—á–∞–µ—Ç —Ä–µ–±—Ä–∞:
# 0 ‚Üí 35:  table_1002132 ‚Üí service_308
# 35 ‚Üí 36: service_308 ‚Üí service_309
# 36 ‚Üí 37: service_309 ‚Üí service_312
# ...
```

**training: —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã**
- `True`: –æ–±—É—á–µ–Ω–∏–µ (dropout –∞–∫—Ç–∏–≤–µ–Ω, BatchNorm –≤ train mode)
- `False`: inference (dropout –≤—ã–∫–ª—é—á–µ–Ω, BatchNorm –≤ eval mode)

---

## 3. Encoder Block

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ
–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —É–∑–ª–æ–≤ (2 —Ñ–∏—á–∏) –≤ –±–æ–≥–∞—Ç—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (64 dims)

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```python
# –°–ª–æ–π 1: –ü–µ—Ä–≤–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
self.lin1 = nn.Linear(in_channels, hidden_channels)     # 2 ‚Üí 64
self.bn1 = nn.BatchNorm1d(hidden_channels)              # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
```

### Forward pass –≤ Encoder

```python
# –®–ê–ì 1: –õ–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
x = self.lin1(x)
# –í—Ö–æ–¥:  [50, 2]
# –í—ã—Ö–æ–¥: [50, 64]
# –§–æ—Ä–º—É–ª–∞: x_out = x_in @ W + b
# W: [2, 64] - –≤–µ—Å–∞, b: [64] - bias

# –®–ê–ì 2: Batch Normalization
x = self.bn1(x)
# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –±–∞—Ç—á—É –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
# –§–æ—Ä–º—É–ª–∞: x_norm = (x - mean) / sqrt(var + eps)

# –®–ê–ì 3: –ê–∫—Ç–∏–≤–∞—Ü–∏—è ReLU
x = F.relu(x)
# –§–æ—Ä–º—É–ª–∞: relu(x) = max(0, x)
# –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å

# –®–ê–ì 4: Dropout (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ training=True)
x = F.dropout(x, p=self.dropout, training=training)
# –°–ª—É—á–∞–π–Ω–æ –æ–±–Ω—É–ª—è–µ—Ç 40% —ç–ª–µ–º–µ–Ω—Ç–æ–≤
# –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ Encoder:**
```python
x: [50, 64]
# –ö–∞–∂–¥—ã–π —É–∑–µ–ª —Ç–µ–ø–µ—Ä—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –≤–µ–∫—Ç–æ—Ä–æ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 64
# –í–º–µ—Å—Ç–æ [is_service, is_table] –∏–º–µ–µ–º –±–æ–≥–∞—Ç–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
```

**–ó–∞—á–µ–º Encoder:**
- –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (2 ‚Üí 64)
- –°–æ–∑–¥–∞–µ—Ç "–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤" –¥–ª—è —É–∑–ª–æ–≤
- –ü–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ —É—á–∏—Ç—å—Å—è —Å–ª–æ–∂–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º

---

## 4. Residual Connection

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ
–î–æ–±–∞–≤–∏—Ç—å "shortcut" –¥–ª—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –∏ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```python
self.lin2 = nn.Linear(hidden_channels, hidden_channels)  # 64 ‚Üí 64
self.bn2 = nn.BatchNorm1d(hidden_channels)
```

### Forward pass —Å Residual

```python
# –®–ê–ì 1: –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ö–æ–¥ (identity)
identity = x  # [50, 64] - –∑–∞–ø–æ–º–∏–Ω–∞–µ–º

# –®–ê–ì 2: –í—Ç–æ—Ä–æ–µ –ª–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
x = self.lin2(x)
# [50, 64] ‚Üí [50, 64]

# –®–ê–ì 3: Batch Normalization
x = self.bn2(x)

# –®–ê–ì 4: –ê–∫—Ç–∏–≤–∞—Ü–∏—è
x = F.relu(x)

# –®–ê–ì 5: Residual connection (–ö–õ–Æ–ß–ï–í–û–ô –ú–û–ú–ï–ù–¢!)
x = x + identity
# –§–æ—Ä–º—É–ª–∞: output = F(x) + x
# –≥–¥–µ F(x) = relu(BN(Linear(x)))
```

**–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Residual:**
```
      x [50, 64]
       ‚Üì         \
    Linear        \
       ‚Üì           \  (skip connection)
   BatchNorm       \
       ‚Üì            \
     ReLU            \
       ‚Üì              ‚Üì
       ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥ (—Å–ª–æ–∂–µ–Ω–∏–µ)
             ‚Üì
    x + identity [50, 64]
```

**–ó–∞—á–µ–º –Ω—É–∂–Ω–∞ residual connection:**

1. **–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã —Ç–µ—á—É—Ç –ª—É—á—à–µ:**
   ```
   –ü—Ä–∏ backpropagation –≥—Ä–∞–¥–∏–µ–Ω—Ç –º–æ–∂–µ—Ç "–æ–±–æ–π—Ç–∏" —Å–ª–æ–π
   ‚àÇLoss/‚àÇx_in = ‚àÇLoss/‚àÇx_out * (‚àÇF/‚àÇx + 1)
                                        ‚Üë
                                 –æ—Ç skip connection
   ```

2. **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è:**
   - –ï—Å–ª–∏ F(x) ‚âà 0, —Ç–æ x ‚âà identity (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤—Ö–æ–¥)
   - –ú–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω—ã–º –∏–∑–º–µ–Ω–µ–Ω–∏—è–º, –Ω–µ —Ä–µ–∑–∫–∏–º

3. **–õ—É—á—à–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:**
   - –ü–æ–º–æ–≥–∞–µ—Ç –æ–±—É—á–∞—Ç—å –≥–ª—É–±–æ–∫–∏–µ —Å–µ—Ç–∏
   - –ò–∑–±–µ–≥–∞–µ—Ç "vanishing gradients"

**–®–ê–ì 6: Dropout**
```python
x = F.dropout(x, p=self.dropout, training=training)
# –í—ã—Ö–æ–¥: [50, 64]
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ Residual Block:**
```python
x: [50, 64]
# –£–ª—É—á—à–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å —É—á–µ—Ç–æ–º residual –æ–±—É—á–µ–Ω–∏—è
```

---

## 5. DAGNN Propagation

### –ß—Ç–æ —ç—Ç–æ —Ç–∞–∫–æ–µ

**DAGNN = Directed Acyclic Graph Neural Network**

–û—Å–Ω–æ–≤–∞–Ω –Ω–∞ **APPNP** (Approximate Personalized Propagation of Neural Predictions)

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ
–†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –º–µ–∂–¥—É —É–∑–ª–∞–º–∏ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –≥—Ä–∞—Ñ–∞

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ DAGNN

```python
class DAGNN(nn.Module):
    def __init__(self, in_channels: int, K: int, dropout: float = 0.5):
        super().__init__()
        self.propagation = APPNP(K=K, alpha=0.1)
        self.att = nn.Parameter(torch.Tensor(K + 1))  # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö hops
        self.dropout = dropout
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `K = 10`: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ propagation hops
- `alpha = 0.1`: teleport probability (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å "–≤–µ—Ä–Ω—É—Ç—å—Å—è" –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é)
- `att`: [11] - –æ–±—É—á–∞–µ–º—ã–µ –≤–µ—Å–∞ –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ hop

### –§–æ—Ä–º—É–ª–∞ APPNP Propagation

–ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ k:

```
H^(k+1) = (1 - Œ±) ¬∑ A ¬∑ H^(k) + Œ± ¬∑ H^(0)
```

**–ì–¥–µ:**
- `H^(k)` - –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —É–∑–ª–æ–≤ –Ω–∞ —à–∞–≥–µ k
- `H^(0)` - –∏—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è (–æ—Ç encoder)
- `A` - –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Å–º–µ–∂–Ω–æ—Å—Ç–∏
- `Œ± = 0.1` - teleport probability

**–ò–Ω—Ç—É–∏—Ü–∏—è:**
- **(1 - Œ±) ¬∑ A ¬∑ H^(k)**: –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –æ—Ç —Å–æ—Å–µ–¥–µ–π (90%)
- **Œ± ¬∑ H^(0)**: "–ø–æ–º–Ω–∏–º" –∏—Å—Ö–æ–¥–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ (10%)
- –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ—Ç —Å–æ—Å–µ–¥–µ–π –∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏

### Forward pass –≤ DAGNN

```python
def forward(self, x, edge_index, training=True):
    # –í—Ö–æ–¥:
    #   x: [50, 64] - —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç encoder
    #   edge_index: [2, 97] - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≥—Ä–∞—Ñ–∞
    
    xs = [x]  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –Ω–∞ –∫–∞–∂–¥–æ–º hop
    
    # –í–µ—Å–∞ —Ä–µ–±–µ—Ä (–≤—Å–µ —Ä–∞–≤–Ω—ã 1.0)
    edge_weight = torch.ones(edge_index.size(1), dtype=torch.float32)
    # [97] - –≤–µ—Å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ 97 —Ä–µ–±–µ—Ä
    
    # –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ: K = 10 hops
    for hop in range(self.propagation.K):  # hop = 0, 1, 2, ..., 9
        
        # PROPAGATION STEP
        x = self.propagation.propagate(edge_index, x=x, edge_weight=edge_weight)
        # –§–æ—Ä–º—É–ª–∞: x_new[i] = Œ£(x[j] * edge_weight[j‚Üíi]) –¥–ª—è –≤—Å–µ—Ö j —Å–æ—Å–µ–¥–µ–π i
        
        # Dropout (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)
        if training:
            x = F.dropout(x, p=self.dropout, training=training)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —ç—Ç–æ–≥–æ hop
        xs.append(x)
    
    # –¢–µ–ø–µ—Ä—å xs —Å–æ–¥–µ—Ä–∂–∏—Ç K+1 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π:
    # xs[0] = H^(0) - –∏—Å—Ö–æ–¥–Ω–æ–µ
    # xs[1] = H^(1) - –ø–æ—Å–ª–µ 1 hop
    # xs[2] = H^(2) - –ø–æ—Å–ª–µ 2 hops
    # ...
    # xs[10] = H^(10) - –ø–æ—Å–ª–µ 10 hops
```

### –î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä –æ–¥–Ω–æ–≥–æ hop

**–ü—Ä–∏–º–µ—Ä –¥–ª—è —É–∑–ª–∞ service_308 (–∏–Ω–¥–µ–∫—Å 35):**

```python
# –î–æ propagation:
x[35] = [0.5, 0.2, 0.8, ..., 0.3]  # 64-–º–µ—Ä–Ω—ã–π –≤–µ–∫—Ç–æ—Ä

# –ù–∞—Ö–æ–¥–∏–º —Å–æ—Å–µ–¥–µ–π –ø–æ edge_index:
# edge_index[:, edge_index[1] == 35] ‚Üí –≤—Ö–æ–¥—è—â–∏–µ —Ä–µ–±—Ä–∞ –≤ —É–∑–µ–ª 35
# –ü—É—Å—Ç—å —Å–æ—Å–µ–¥–∏: [0, 34] (table_1002132 –∏ service_307)

# –ê–≥—Ä–µ–≥–∞—Ü–∏—è:
x_new[35] = (1 - 0.1) * (x[0] + x[34]) / 2 + 0.1 * x_original[35]
          = 0.9 * mean(neighbors) + 0.1 * original
          
# –ü–æ—Å–ª–µ propagation:
x[35] = [0.52, 0.25, 0.75, ..., 0.28]  # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä
```

**–ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç:**
1. –£–∑–µ–ª –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ—Å–µ–¥–µ–π
2. 90% - –æ—Ç —Å–æ—Å–µ–¥–µ–π, 10% - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–≤–æ–µ –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
3. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è "—Ç–µ—á–µ—Ç" –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é —Ä–µ–±–µ—Ä

### Attention –¥–ª—è —Ä–∞–∑–Ω—ã—Ö hops

–ü–æ—Å–ª–µ K hops –∏–º–µ–µ–º K+1 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π. –ù—É–∂–Ω–æ –∏—Ö –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å:

```python
# –°–∫–ª–∞–¥—ã–≤–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤ –æ–¥–∏–Ω —Ç–µ–Ω–∑–æ—Ä
out = torch.stack(xs, dim=-1)
# –†–∞–∑–º–µ—Ä: [50, 64, 11]
#         —É–∑–ª—ã √ó dims √ó hops

# –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ hop
att_weights = F.softmax(self.att, dim=0)
# self.att: [11] - –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
# att_weights: [11] - –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ (—Å—É–º–º–∞ = 1)
# –ü—Ä–∏–º–µ—Ä: [0.05, 0.08, 0.12, 0.15, 0.20, 0.15, 0.10, 0.08, 0.04, 0.02, 0.01]

# –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ –ø–æ hops
out = (out * att_weights.view(1, 1, -1)).sum(dim=-1)
# –§–æ—Ä–º—É–ª–∞: out[node, dim] = Œ£(xs[k][node, dim] * att_weights[k]) for k in 0..K
# –†–∞–∑–º–µ—Ä: [50, 64]
```

**–ó–∞—á–µ–º attention –¥–ª—è hops:**
- –†–∞–∑–Ω—ã–µ hops —Å–æ–¥–µ—Ä–∂–∞—Ç —Ä–∞–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
- Hop 0: –ª–æ–∫–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —É–∑–ª–∞
- Hop 1-2: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç –ø—Ä—è–º—ã—Ö —Å–æ—Å–µ–¥–µ–π  
- Hop 3-5: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç –¥–∞–ª—å–Ω–∏—Ö —É–∑–ª–æ–≤
- Hop 6-10: –≥–ª–æ–±–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞
- **–ú–æ–¥–µ–ª—å –°–ê–ú–ê —É—á–∏—Ç—Å—è**, –∫–∞–∫–∏–µ hops –≤–∞–∂–Ω–µ–µ!

**–ü—Ä–∏–º–µ—Ä –≤–µ—Å–æ–≤ –≤–Ω–∏–º–∞–Ω–∏—è:**
```
att_weights = [0.05, 0.08, 0.12, 0.15, 0.20, 0.15, 0.10, 0.08, 0.04, 0.02, 0.01]
               ‚Üë     ‚Üë     ‚Üë     ‚Üë     ‚Üë     ‚Üë     ‚Üë     ‚Üë     ‚Üë     ‚Üë     ‚Üë
              hop0  hop1  hop2  hop3  hop4  hop5  hop6  hop7  hop8  hop9  hop10

–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –Ω–∞ hop 4 (0.20) ‚Üí –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è 4 —à–∞–≥–∞ –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω–∞
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç DAGNN Propagation:**
```python
x: [50, 64]
# –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —É–∑–ª–æ–≤ —Å —É—á–µ—Ç–æ–º –í–°–ï–ì–û –≥—Ä–∞—Ñ–∞
# –ö–∞–∂–¥—ã–π —É–∑–µ–ª "–∑–Ω–∞–µ—Ç" –æ —Å–≤–æ–∏—Ö —Å–æ—Å–µ–¥—è—Ö (—á–µ—Ä–µ–∑ propagation)
```

---

### –ü–æ–¥—Ä–æ–±–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ APPNP

**–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è:**
```
H^(0) = x  # –ò—Å—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç encoder
```

**–ò—Ç–µ—Ä–∞—Ü–∏—è (–¥–ª—è –∫–∞–∂–¥–æ–≥–æ hop k = 1, 2, ..., K):**
```
H^(k) = (1 - Œ±) ¬∑ D^(-1/2) ¬∑ A ¬∑ D^(-1/2) ¬∑ H^(k-1) + Œ± ¬∑ H^(0)
```

**–ì–¥–µ:**
- `A`: –º–∞—Ç—Ä–∏—Ü–∞ —Å–º–µ–∂–Ω–æ—Å—Ç–∏ (–∏–∑ edge_index)
- `D`: –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ç–µ–ø–µ–Ω–µ–π —É–∑–ª–æ–≤
- `Œ± = 0.1`: teleport probability
- `D^(-1/2) ¬∑ A ¬∑ D^(-1/2)`: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ (—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)

**–í –∫–æ–¥–µ (—É–ø—Ä–æ—â–µ–Ω–Ω–æ):**
```python
H_0 = x  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ
H = x

for k in range(K):
    # Propagate: –∞–≥—Ä–µ–≥–∞—Ü–∏—è –æ—Ç —Å–æ—Å–µ–¥–µ–π
    H = propagate(edge_index, H)  # –ú–∞—Ç—Ä–∏—á–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
    
    # Teleport: –¥–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
    H = (1 - alpha) * H + alpha * H_0
    # H = 0.9 * (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç —Å–æ—Å–µ–¥–µ–π) + 0.1 * (–∏—Å—Ö–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)
```

**–ü—Ä–∏–º–µ—Ä —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è (service_308):**

```
Hop 0: [0.5, 0.2, 0.8, ...]  ‚Üê –∏—Å—Ö–æ–¥–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥

Hop 1: –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –æ—Ç table_1002132
       [0.52, 0.25, 0.75, ...] = 0.9 * (—ç–º–±–µ–¥–¥–∏–Ω–≥ table) + 0.1 * hop0

Hop 2: –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –æ—Ç —Å–æ—Å–µ–¥–µ–π hop 1
       [0.48, 0.30, 0.70, ...] = 0.9 * (—Å–æ—Å–µ–¥–∏) + 0.1 * hop0

...

Hop 10: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç –≤—Å–µ–≥–æ –≥—Ä–∞—Ñ–∞
        [0.55, 0.28, 0.72, ...]
```

---

## 6. Classifier

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ
–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —É–∑–ª–æ–≤ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```python
# –£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
self.lin3 = nn.Linear(hidden_channels, hidden_channels // 2)  # 64 ‚Üí 32
self.bn3 = nn.BatchNorm1d(hidden_channels // 2)

# –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
self.lin_out = nn.Linear(hidden_channels // 2, out_channels)  # 32 ‚Üí 15
```

### Forward pass –≤ Classifier

```python
# –ü–û–°–õ–ï DAGNN –∏–º–µ–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤—Å–µ—Ö 50 —É–∑–ª–æ–≤: [50, 64]
x = self.dagnn(x, edge_index, training=training)

# –®–ê–ì 1: –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Å–ª–æ–π
x = self.lin3(x)
# [50, 64] ‚Üí [50, 32]
# –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

# –®–ê–ì 2: Batch Normalization
x = self.bn3(x)

# –®–ê–ì 3: –ê–∫—Ç–∏–≤–∞—Ü–∏—è
x = F.relu(x)

# –®–ê–ì 4: Dropout
x = F.dropout(x, p=self.dropout, training=training)

# –®–ê–ì 5: –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (–§–ò–ù–ê–õ–¨–ù–´–ï –õ–û–ì–ò–¢–´)
x = self.lin_out(x)
# [50, 32] ‚Üí [50, 15]
# –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ 50 —É–∑–ª–æ–≤ - 15 –ª–æ–≥–∏—Ç–æ–≤ (–æ—Ü–µ–Ω–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞)
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç Classifier:**
```python
x: [50, 15]
# –î–ª—è –∫–∞–∂–¥–æ–≥–æ —É–∑–ª–∞: 15 –ª–æ–≥–∏—Ç–æ–≤ (–æ—Ü–µ–Ω–æ–∫) –¥–ª—è 15 –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤

# –ü—Ä–∏–º–µ—Ä –¥–ª—è —É–∑–ª–∞ 35 (service_308):
x[35] = [-2.1, -1.8, 3.5, 2.1, -0.5, ..., -1.0]
         ‚Üë     ‚Üë     ‚Üë    ‚Üë
       s_306 s_307 s_308 s_309
```

**–ó–∞—á–µ–º –º–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–π classifier:**
- `64 ‚Üí 32`: –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–∂–∞—Ç–∏–µ
- `32 ‚Üí 15`: —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è
- BatchNorm + ReLU –º–µ–∂–¥—É —Å–ª–æ—è–º–∏: –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
- Dropout: —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è

---

## 7. –ü–æ–ª–Ω—ã–π Forward Pass

### –®–∞–≥ –∑–∞ —à–∞–≥–æ–º —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –ø—Ä–∏–º–µ—Ä–æ–º

**–ó–∞–¥–∞—á–∞:**
```
–ö–æ–Ω—Ç–µ–∫—Å—Ç: ('table_1002132', 'service_308')
–ù—É–∂–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å: —Å–ª–µ–¥—É—é—â–∏–π —Å–µ—Ä–≤–∏—Å
```

### –®–ê–ì 0: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

```python
# –ì—Ä–∞—Ñ (–≤—Å–µ 50 —É–∑–ª–æ–≤)
x = tensor([
    [0, 1],  # —É–∑–µ–ª 0: table_1002132
    ...
    [1, 0],  # —É–∑–µ–ª 35: service_308
    ...
])  # [50, 2]

edge_index = tensor([
    [0, 35, ...],  # –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    [35, 36, ...]  # –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
])  # [2, 97]

# –ö–æ–Ω—Ç–µ–∫—Å—Ç (–∏–Ω–¥–µ–∫—Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —É–∑–ª–∞)
context_id = 35  # service_308 –≤ node_map
```

---

### –®–ê–ì 1: ENCODER

```python
# 1.1: Linear projection
x = self.lin1(x)  # [50, 2] ‚Üí [50, 64]

# –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–ø—Ä–∏–º–µ—Ä):
x[0] = [0.3, 0.5, 0.2, ..., 0.8]    # table_1002132
x[35] = [0.6, 0.4, 0.7, ..., 0.5]   # service_308

# 1.2: BatchNorm + ReLU + Dropout
x = F.dropout(F.relu(self.bn1(x)), p=0.4, training=True)
# [50, 64]
```

**–ß—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ:**
- –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ [0,1] –∏–ª–∏ [1,0] –ø—Ä–µ–≤—Ä–∞—Ç–∏–ª–∏—Å—å –≤ –±–æ–≥–∞—Ç—ã–µ –≤–µ–∫—Ç–æ—Ä—ã —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 64
- –ö–∞–∂–¥—ã–π —É–∑–µ–ª —Ç–µ–ø–µ—Ä—å –∏–º–µ–µ—Ç "–Ω–∞—á–∞–ª—å–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥"

---

### –®–ê–ì 2: RESIDUAL BLOCK

```python
# 2.1: –°–æ—Ö—Ä–∞–Ω—è–µ–º identity
identity = x  # [50, 64]

# 2.2: –í—Ç–æ—Ä–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
x = self.lin2(x)  # [50, 64] ‚Üí [50, 64]
x = self.bn2(x)
x = F.relu(x)

# 2.3: RESIDUAL CONNECTION
x = x + identity  # –ö–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç!

# 2.4: Dropout
x = F.dropout(x, p=0.4, training=True)
# [50, 64]
```

**–ß—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ:**
- –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ "—É–ª—É—á—à–µ–Ω—ã" —á–µ—Ä–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–ª–æ–π
- Skip connection —Å–æ—Ö—Ä–∞–Ω–∏–ª –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

---

### –®–ê–ì 3: DAGNN PROPAGATION (10 hops)

```python
# –ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
H_0 = x  # [50, 64]
xs = [H_0]  # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π

# HOP 1
H_1 = self.propagation.propagate(edge_index, x=H_0, edge_weight=edge_weight)
# –§–æ—Ä–º—É–ª–∞: H_1 = (1-0.1) * A*H_0 + 0.1*H_0 = 0.9*A*H_0 + 0.1*H_0

# –ü—Ä–∏–º–µ—Ä –¥–ª—è service_308 (—É–∑–µ–ª 35):
# –í—Ö–æ–¥—è—â–∏–µ —Å–æ—Å–µ–¥–∏: —É–∑–µ–ª 0 (table_1002132)
H_1[35] = 0.9 * H_0[0] + 0.1 * H_0[35]
        = 0.9 * [0.3, 0.5, ...] + 0.1 * [0.6, 0.4, ...]
        = [0.33, 0.49, ...]

xs.append(H_1)  # –°–æ—Ö—Ä–∞–Ω—è–µ–º

# HOP 2
H_2 = self.propagation.propagate(edge_index, x=H_1, edge_weight=edge_weight)
# –¢–µ–ø–µ—Ä—å service_308 –ø–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç —Å–æ—Å–µ–¥–µ–π –µ–≥–æ —Å–æ—Å–µ–¥–µ–π

xs.append(H_2)

# ... –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –¥–æ HOP 10 ...

# HOP 10
H_10 = self.propagation.propagate(edge_index, x=H_9, edge_weight=edge_weight)
xs.append(H_10)
```

**–ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ –∫–∞–∂–¥–æ–º hop:**

```
Hop 0: [50, 64] - –∏—Å—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏

Hop 1: [50, 64] - —É–∑–ª—ã –∑–Ω–∞—é—Ç –æ –ø—Ä—è–º—ã—Ö —Å–æ—Å–µ–¥—è—Ö
  service_308 ‚Üê table_1002132
  service_309 ‚Üê service_308

Hop 2: [50, 64] - —É–∑–ª—ã –∑–Ω–∞—é—Ç –æ —Å–æ—Å–µ–¥—è—Ö —Å–æ—Å–µ–¥–µ–π
  service_309 ‚Üê service_308 ‚Üê table_1002132
  
Hop 3-10: [50, 64] - —É–∑–ª—ã –∑–Ω–∞—é—Ç –æ –≤—Å–µ –±–æ–ª–µ–µ –¥–∞–ª—å–Ω–∏—Ö —É–∑–ª–∞—Ö
  –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ –≤—Å–µ–º—É –≥—Ä–∞—Ñ—É
```

**–§–æ—Ä–º—É–ª–∞ propagate (–¥–µ—Ç–∞–ª—å–Ω–æ):**

–î–ª—è —É–∑–ª–∞ i:
```
h_new[i] = (1/sqrt(deg[i])) * Œ£ (h[j] / sqrt(deg[j])) 
                               j‚ààN(i)

–≥–¥–µ:
  N(i) - –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ—Å–µ–¥–µ–π —É–∑–ª–∞ i
  deg[i] - —Å—Ç–µ–ø–µ–Ω—å —É–∑–ª–∞ i
  h[j] - —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ—Å–µ–¥–∞ j
```

–° teleport:
```
h_final[i] = (1 - Œ±) * h_new[i] + Œ± * h_0[i]
           = 0.9 * h_new[i] + 0.1 * h_0[i]
```

### Attention aggregation

```python
# –ü–æ—Å–ª–µ 10 hops –∏–º–µ–µ–º 11 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
out = torch.stack(xs, dim=-1)  # [50, 64, 11]

# –í–µ—Å–∞ attention (–æ–±—É—á–∞–µ–º—ã–µ)
att_weights = F.softmax(self.att, dim=0)
# [11] - –≤–µ—Å–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ hop
# –ü—Ä–∏–º–µ—Ä: [0.08, 0.09, 0.11, 0.13, 0.15, 0.14, 0.12, 0.09, 0.05, 0.03, 0.01]

# –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞
out = (out * att_weights.view(1, 1, -1)).sum(dim=-1)
# [50, 64]

# –î–ª—è —É–∑–ª–∞ i –∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ d:
out[i, d] = Œ£(xs[k][i, d] * att_weights[k]) for k=0..10
```

**–ü—Ä–∏–º–µ—Ä –¥–ª—è service_308:**
```python
# –≠–º–±–µ–¥–¥–∏–Ω–≥ –ø–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 0:
xs[0][35, 0] = 0.6   (hop 0, –∏—Å—Ö–æ–¥–Ω—ã–π)
xs[1][35, 0] = 0.55  (hop 1, —Å —Å–æ—Å–µ–¥—è–º–∏)
xs[2][35, 0] = 0.52  (hop 2)
...
xs[10][35, 0] = 0.48 (hop 10)

# Attention weights:
att = [0.08, 0.09, 0.11, ..., 0.01]

# –ò—Ç–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:
out[35, 0] = 0.6*0.08 + 0.55*0.09 + 0.52*0.11 + ... + 0.48*0.01
           = 0.534  # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –≤—Å–µ—Ö hops
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç DAGNN Propagation:**
```python
x: [50, 64]
# –ö–∞–∂–¥—ã–π —É–∑–µ–ª —Ç–µ–ø–µ—Ä—å —Å–æ–¥–µ—Ä–∂–∏—Ç:
# - –°–≤–æ—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
# - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç —Å–æ—Å–µ–¥–µ–π (1-2 hops)
# - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç –¥–∞–ª—å–Ω–∏—Ö —É–∑–ª–æ–≤ (3-10 hops)
# - –ì–ª–æ–±–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≥—Ä–∞—Ñ–∞
```

**–ó–∞—á–µ–º DAGNN Propagation:**
- **–ì–ª–∞–≤–Ω–∞—è —Ñ–∏—à–∫–∞ –º–æ–¥–µ–ª–∏!**
- –£–∑–ª—ã –æ–±–º–µ–Ω–∏–≤–∞—é—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
- service_308 "—É–∑–Ω–∞–µ—Ç" –æ table_1002132 –∏ service_309
- –ú–æ–¥–µ–ª—å –ø–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

---

### –®–ê–ì 4: CLASSIFIER

```python
# –í—Ö–æ–¥: —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤—Å–µ—Ö 50 —É–∑–ª–æ–≤ –ø–æ—Å–ª–µ DAGNN
x: [50, 64]

# 4.1: –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Å–ª–æ–π
x = self.lin3(x)  # [50, 64] ‚Üí [50, 32]
x = self.bn3(x)
x = F.relu(x)
x = F.dropout(x, p=0.4, training=True)

# 4.2: –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
x = self.lin_out(x)  # [50, 32] ‚Üí [50, 15]
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```python
x: [50, 15]
# –î–ª—è –∫–∞–∂–¥–æ–≥–æ —É–∑–ª–∞ - 15 –ª–æ–≥–∏—Ç–æ–≤ (–æ—Ü–µ–Ω–æ–∫) –¥–ª—è 15 —Å–µ—Ä–≤–∏—Å–æ–≤

# –ü—Ä–∏–º–µ—Ä –¥–ª—è service_308 (—É–∑–µ–ª 35):
x[35] = [-2.1, -1.8, 3.5, 2.1, -0.5, -1.2, -0.8, ...]
         ‚Üë     ‚Üë     ‚Üë    ‚Üë
       s_306 s_307 s_308 s_309
       
# –í—ã—Å–æ–∫–∏–π –ª–æ–≥–∏—Ç (3.5) –¥–ª—è service_308
# –°—Ä–µ–¥–Ω–∏–π –ª–æ–≥–∏—Ç (2.1) –¥–ª—è service_309
# –ù–∏–∑–∫–∏–µ –ª–æ–≥–∏—Ç—ã –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö
```

---

### –®–ê–ì 5: –í—ã–±–æ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

```python
# –í –æ–±—É—á–µ–Ω–∏–∏/inference –º—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –í–°–ï 50 —É–∑–ª–æ–≤
# –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —É–∑–ª—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤!

# –ö–æ–Ω—Ç–µ–∫—Å—Ç—ã train (–∏–Ω–¥–µ–∫—Å—ã –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —É–∑–ª–æ–≤)
contexts_train = [0, 35, 36, ...]  # [87]

# –ë–µ—Ä–µ–º –ª–æ–≥–∏—Ç—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —É–∑–ª–æ–≤
out = x[contexts_train]  # [87, 15]

# –ü—Ä–∏–º–µ—Ä:
# –ö–æ–Ω—Ç–µ–∫—Å—Ç 0: ('table_1002132', 'service_308')
# context_id = 35 (service_308)
# out[0] = x[35] = [-2.1, -1.8, 3.5, 2.1, ...]
```

**–ó–∞—á–µ–º –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —É–∑–ª—ã:**
- –£ –Ω–∞—Å 87 –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
- –ö–∞–∂–¥—ã–π –ø—Ä–∏–º–µ—Ä –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º —É–∑–ª–æ–º (–∫–æ–Ω—Ç–µ–∫—Å—Ç)
- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–µ–ª–∞–µ–º "–æ—Ç –∏–º–µ–Ω–∏" —ç—Ç–æ–≥–æ —É–∑–ª–∞
- –ù–µ –Ω—É–∂–Ω—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö 50 —É–∑–ª–æ–≤, —Ç–æ–ª—å–∫–æ –¥–ª—è 87 –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö

---

### –®–ê–ì 6: –û–±—É—á–µ–Ω–∏–µ (Training)

```python
# –õ–æ–≥–∏—Ç—ã –¥–ª—è train –ø—Ä–∏–º–µ—Ä–æ–≤
out = model(data_pyg.x, data_pyg.edge_index, training=True)[contexts_train]
# [87, 15]

# –¶–µ–ª–µ–≤—ã–µ –∫–ª–∞—Å—Å—ã
targets_train = [2, 3, 2, 8, ...]  # [87] - –∏–Ω–¥–µ–∫—Å—ã –≤ service_map

# Loss function
loss = F.cross_entropy(out, targets_train)
```

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç Cross Entropy:**

```python
# –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞:
# 1. Softmax –∫ –ª–æ–≥–∏—Ç–∞–º
probs = softmax(out[i])
# [-2.1, -1.8, 3.5, 2.1, ...] ‚Üí [0.01, 0.02, 0.68, 0.19, ...]

# 2. –ë–µ—Ä–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞
true_class = targets_train[i]  # –ù–∞–ø—Ä–∏–º–µ—Ä, 3 (service_309)
p_true = probs[true_class]      # 0.19

# 3. –í—ã—á–∏—Å–ª—è–µ–º loss
loss_i = -log(p_true) = -log(0.19) = 1.66

# 4. –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ –≤—Å–µ–º 87 –ø—Ä–∏–º–µ—Ä–∞–º
loss = mean(loss_i for all i)
```

**Backpropagation:**
```python
loss.backward()  # –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
optimizer.step()  # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞
```

---

### –®–ê–ì 7: Inference (–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ)

```python
model.eval()  # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏

with torch.no_grad():  # –ë–µ–∑ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    # Forward pass
    test_output = model(data_pyg.x, data_pyg.edge_index, training=False)
    # [50, 15] - –ª–æ–≥–∏—Ç—ã –¥–ª—è –≤—Å–µ—Ö —É–∑–ª–æ–≤
    
    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ test –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã
    test_output = test_output[contexts_test]
    # [38, 15] - –ª–æ–≥–∏—Ç—ã –¥–ª—è 38 —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
    
    # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
    probs = F.softmax(test_output, dim=1)
    # [38, 15] - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    preds = test_output.argmax(dim=1)
    # [38] - –∏–Ω–¥–µ–∫—Å—ã –∫–ª–∞—Å—Å–æ–≤ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
```

**–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä:**

```python
# –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä 0:
# –ö–æ–Ω—Ç–µ–∫—Å—Ç: ('table_1002132', 'service_308')
# context_id = 35

# –õ–æ–≥–∏—Ç—ã
logits = test_output[0] = [-2.1, -1.8, 3.5, 2.1, -0.5, ...]

# –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ—Å–ª–µ softmax
probs = [0.01, 0.02, 0.68, 0.19, 0.01, ...]
         ‚Üë     ‚Üë     ‚Üë     ‚Üë
       s_306 s_307 s_308 s_309
       (0)   (1)   (2)   (3)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
pred = argmax(probs) = 2  # –∏–Ω–¥–µ–∫—Å –≤ service_map

# –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞
predicted_service = service_map_inverse[2] = 'service_308'

# –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
true_service = 'service_309' (–∫–ª–∞—Å—Å 3)

# –†–µ–∑—É–ª—å—Ç–∞—Ç: ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ (mode collapse!)
```

---

## 8. –ü–æ–ª–Ω–∞—è —Å—Ö–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ

### 8.1: –î–∞–Ω–Ω—ã–µ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Ä–∞–±–æ—Ç—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  –ö–æ–º–ø–æ–∑–∏—Ü–∏–∏ (943) ‚Üí –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø—É—Ç–∏ (106)              ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ  –û–±—É—á–∞—é—â–∏–µ –ø—Ä–∏–º–µ—Ä—ã (125):                               ‚îÇ
‚îÇ    X_raw: [('table_X',), ('table_X', 'service_308'), ...]‚îÇ
‚îÇ    y_raw: ['service_308', 'service_309', ...]           ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ  –ì—Ä–∞—Ñ (NetworkX):                                        ‚îÇ
‚îÇ    - 50 —É–∑–ª–æ–≤ —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏ (type: service/table)       ‚îÇ
‚îÇ    - 97 –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ä–µ–±–µ—Ä                              ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ  PyTorch Geometric Data:                                 ‚îÇ
‚îÇ    - x: [50, 2] - –ø—Ä–∏–∑–Ω–∞–∫–∏ —É–∑–ª–æ–≤                       ‚îÇ
‚îÇ    - edge_index: [2, 97] - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≥—Ä–∞—Ñ–∞             ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ  –ú–∞–ø–ø–∏–Ω–≥–∏:                                               ‚îÇ
‚îÇ    - node_map: {—É–∑–µ–ª ‚Üí –∏–Ω–¥–µ–∫—Å 0-49}                    ‚îÇ
‚îÇ    - service_map: {—Å–µ—Ä–≤–∏—Å ‚Üí –∏–Ω–¥–µ–∫—Å 0-14}               ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ  –ò–Ω–¥–µ–∫—Å—ã:                                                ‚îÇ
‚îÇ    - contexts: [125] - –∏–Ω–¥–µ–∫—Å—ã —É–∑–ª–æ–≤ –≤ node_map        ‚îÇ
‚îÇ    - targets: [125] - –∏–Ω–¥–µ–∫—Å—ã —Å–µ—Ä–≤–∏—Å–æ–≤ –≤ service_map   ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ  Train/Test Split:                                       ‚îÇ
‚îÇ    - 87 train / 38 test                                 ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FORWARD PASS –í –ú–û–î–ï–õ–ò                                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  INPUT:                                                  ‚îÇ
‚îÇ    x: [50, 2] - –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤—Å–µ—Ö —É–∑–ª–æ–≤                    ‚îÇ
‚îÇ    edge_index: [2, 97] - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≥—Ä–∞—Ñ–∞               ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îÇ
‚îÇ  ‚îÇ  ENCODER BLOCK             ‚îÇ                         ‚îÇ
‚îÇ  ‚îÇ  Linear(2 ‚Üí 64)            ‚îÇ ‚Üê in_channels          ‚îÇ
‚îÇ  ‚îÇ  + BatchNorm + ReLU        ‚îÇ                         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ    [50, 64]                                             ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îÇ
‚îÇ  ‚îÇ  RESIDUAL BLOCK            ‚îÇ                         ‚îÇ
‚îÇ  ‚îÇ  Linear(64 ‚Üí 64)           ‚îÇ ‚Üê hidden_channels      ‚îÇ
‚îÇ  ‚îÇ  + BatchNorm + ReLU        ‚îÇ                         ‚îÇ
‚îÇ  ‚îÇ  + Skip Connection         ‚îÇ ‚Üê RESIDUAL!            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ    [50, 64]                                             ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îÇ
‚îÇ  ‚îÇ  DAGNN PROPAGATION         ‚îÇ                         ‚îÇ
‚îÇ  ‚îÇ  K=10 hops                 ‚îÇ ‚Üê K                    ‚îÇ
‚îÇ  ‚îÇ  Œ±=0.1 teleport            ‚îÇ                         ‚îÇ
‚îÇ  ‚îÇ  + Attention weights       ‚îÇ ‚Üê –æ–±—É—á–∞–µ–º—ã–µ –≤–µ—Å–∞       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ    [50, 64] —Å –≥—Ä–∞—Ñ–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π                     ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îÇ
‚îÇ  ‚îÇ  CLASSIFIER                ‚îÇ                         ‚îÇ
‚îÇ  ‚îÇ  Linear(64 ‚Üí 32)           ‚îÇ                         ‚îÇ
‚îÇ  ‚îÇ  + BatchNorm + ReLU        ‚îÇ                         ‚îÇ
‚îÇ  ‚îÇ  Linear(32 ‚Üí 15)           ‚îÇ ‚Üê out_channels         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ  OUTPUT:                                                 ‚îÇ
‚îÇ    [50, 15] - –ª–æ–≥–∏—Ç—ã –¥–ª—è –≤—Å–µ—Ö —É–∑–ª–æ–≤                    ‚îÇ
‚îÇ         ‚Üì                                                ‚îÇ
‚îÇ  –í—ã–±–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —É–∑–ª–æ–≤:                               ‚îÇ
‚îÇ    out[contexts_train] ‚Üí [87, 15]                       ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  –û–ë–£–ß–ï–ù–ò–ï / –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  Training:                                               ‚îÇ
‚îÇ    loss = CrossEntropy(out, targets_train)              ‚îÇ
‚îÇ    loss.backward() ‚Üí –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤                   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Inference:                                              ‚îÇ
‚îÇ    probs = softmax(out) ‚Üí [87, 15]                     ‚îÇ
‚îÇ    preds = argmax(probs) ‚Üí [87]                        ‚îÇ
‚îÇ    predicted_services = [service_map_inverse[p] for p]  ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 9. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ —ç—Ç–∞–ø–∞–º

### –¢–∞–±–ª–∏—Ü–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö

| –î–∞–Ω–Ω—ã–µ | –ì–¥–µ —Å–æ–∑–¥–∞—é—Ç—Å—è | –ì–¥–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è | –ó–∞—á–µ–º |
|--------|---------------|------------------|-------|
| **x** [50, 2] | prepare_pytorch_geometric_data | –í—Ö–æ–¥ –º–æ–¥–µ–ª–∏ | –ò—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —É–∑–ª–æ–≤ |
| **edge_index** [2, 97] | prepare_pytorch_geometric_data | DAGNN propagation | –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≥—Ä–∞—Ñ–∞ |
| **node_map** | prepare_pytorch_geometric_data | –°–æ–∑–¥–∞–Ω–∏–µ contexts | –ú–∞–ø–ø–∏–Ω–≥ —É–∑–ª–æ–≤ ‚Üí –∏–Ω–¥–µ–∫—Å—ã |
| **service_map** | prepare_pytorch_geometric_data | –°–æ–∑–¥–∞–Ω–∏–µ targets, —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ | –ú–∞–ø–ø–∏–Ω–≥ —Å–µ—Ä–≤–∏—Å–æ–≤ ‚Üí –∫–ª–∞—Å—Å—ã |
| **contexts** [125] | prepare_pytorch_geometric_data | –í—ã–±–æ—Ä —É–∑–ª–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è | –ò–Ω–¥–µ–∫—Å—ã –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —É–∑–ª–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ |
| **targets** [125] | prepare_pytorch_geometric_data | Loss function | –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã |
| **H^(0)** [50, 64] | Encoder | DAGNN (–∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ) | –ù–∞—á–∞–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ |
| **H^(k)** [50, 64] | DAGNN (–∫–∞–∂–¥—ã–π hop) | Attention aggregation | –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–æ—Å–ª–µ k hops |
| **att_weights** [11] | DAGNN (–æ–±—É—á–∞–µ–º—ã–µ) | –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ hops | –í–µ—Å–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ hop |
| **out** [87, 15] | Classifier ‚Üí contexts_train | CrossEntropyLoss | –õ–æ–≥–∏—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è |

---

## 10. –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª—ã (–ø–æ–ª–Ω—ã–µ)

### 10.1: Encoder

```
H^(0) = ReLU(BN(x ¬∑ W_1 + b_1))

–≥–¥–µ:
  x: [50, 2] - –≤—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
  W_1: [2, 64] - –≤–µ—Å–∞ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è
  b_1: [64] - bias
  BN: Batch Normalization
  H^(0): [50, 64] - –Ω–∞—á–∞–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
```

### 10.2: Residual Block

```
H^(res) = ReLU(BN(H^(0) ¬∑ W_2 + b_2)) + H^(0)

–≥–¥–µ:
  W_2: [64, 64] - –≤–µ—Å–∞
  + H^(0) - skip connection (residual)
```

### 10.3: DAGNN Propagation (APPNP)

**–î–ª—è –∫–∞–∂–¥–æ–≥–æ hop k = 1, 2, ..., K:**

```
H^(k) = (1 - Œ±) ¬∑ D^(-1/2) ¬∑ A ¬∑ D^(-1/2) ¬∑ H^(k-1) + Œ± ¬∑ H^(0)

–≥–¥–µ:
  A[i,j] = 1, –µ—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–±—Ä–æ i ‚Üí j, –∏–Ω–∞—á–µ 0
  D[i,i] = —Å—Ç–µ–ø–µ–Ω—å —É–∑–ª–∞ i (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ö–æ–¥—è—â–∏—Ö + –∏—Å—Ö–æ–¥—è—â–∏—Ö —Ä–µ–±–µ—Ä)
  Œ± = 0.1 - teleport probability
  H^(0) - –∏—Å—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (–æ—Ç encoder + residual)
```

**–î–ª—è —É–∑–ª–∞ i:**
```
h_i^(k) = (1 - Œ±) ¬∑ Œ£(h_j^(k-1) / sqrt(deg_i * deg_j)) + Œ± ¬∑ h_i^(0)
                    j‚ààN_in(i)

–≥–¥–µ:
  N_in(i) - –≤—Ö–æ–¥—è—â–∏–µ —Å–æ—Å–µ–¥–∏ —É–∑–ª–∞ i
  deg_i - —Å—Ç–µ–ø–µ–Ω—å —É–∑–ª–∞ i
```

**Attention aggregation:**
```
H^(final) = Œ£(w_k ¬∑ H^(k)) –¥–ª—è k = 0, 1, ..., K

–≥–¥–µ:
  w_k = softmax(att)[k] - –æ–±—É—á–∞–µ–º—ã–µ –≤–µ—Å–∞ attention
  att: [K+1] - –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
```

### 10.4: Classifier

```
logits = Linear_out(ReLU(BN(Linear_3(H^(final)))))

–î–µ—Ç–∞–ª—å–Ω–æ:
  z_1 = H^(final) ¬∑ W_3 + b_3      # [50, 64] ‚Üí [50, 32]
  z_2 = ReLU(BN(z_1))              # –ê–∫—Ç–∏–≤–∞—Ü–∏—è + –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
  logits = z_2 ¬∑ W_out + b_out     # [50, 32] ‚Üí [50, 15]

–≥–¥–µ:
  W_3: [64, 32]
  W_out: [32, 15]
```

### 10.5: Loss Function

```
L = CrossEntropy(logits[contexts], targets)
  = -(1/N) Œ£ log(softmax(logits[i])[targets[i]])
  
–≥–¥–µ:
  N = 87 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ train –ø—Ä–∏–º–µ—Ä–æ–≤
  logits[i]: [15] - –ª–æ–≥–∏—Ç—ã –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ i
  targets[i] - –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª–∞—Å—Å (0-14)
```

---

## 11. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä: –ø–æ–ª–Ω—ã–π –ø—Ä–æ—Ö–æ–¥

### –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

```python
# –û–±—É—á–∞—é—â–∏–π –ø—Ä–∏–º–µ—Ä:
context = ('table_1002132', 'service_308')
target = 'service_309'

# –ü–æ—Å–ª–µ –º–∞–ø–ø–∏–Ω–≥–∞:
context_node_id = 35  # service_308 –≤ node_map
target_class_id = 3   # service_309 –≤ service_map
```

### –ü—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å

```
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
ENCODER
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

–í—Ö–æ–¥: x[35] = [1, 0]  (service_308 - —ç—Ç–æ —Å–µ—Ä–≤–∏—Å)
      ‚Üì Linear(2 ‚Üí 64)
      [0.6, 0.4, 0.7, 0.3, ..., 0.5]  (64 dims)
      ‚Üì BatchNorm + ReLU + Dropout
H^(0)[35] = [0.62, 0.38, 0.72, ..., 0.48]

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
RESIDUAL BLOCK
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

      ‚Üì Linear(64 ‚Üí 64) + BN + ReLU
F(x) = [0.65, 0.42, 0.68, ..., 0.52]
      ‚Üì + identity
H^(res)[35] = [0.63, 0.40, 0.70, ..., 0.50]

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
DAGNN PROPAGATION
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Hop 0: [0.63, 0.40, 0.70, ..., 0.50]

Hop 1: –ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –æ—Ç table_1002132 (—É–∑–µ–ª 0)
       [0.58, 0.45, 0.65, ..., 0.48]
       = 0.9*(—ç–º–± table) + 0.1*(hop 0)

Hop 2: –ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –æ—Ç —Å–æ—Å–µ–¥–µ–π hop 1
       [0.60, 0.42, 0.68, ..., 0.52]

Hop 3: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –¥–∞–ª—å—à–µ
       [0.59, 0.44, 0.66, ..., 0.51]

...

Hop 10: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç –≤—Å–µ–≥–æ –≥—Ä–∞—Ñ–∞
        [0.61, 0.43, 0.67, ..., 0.49]

Attention aggregation:
  att_weights = [0.08, 0.09, 0.11, 0.13, 0.15, ...]
  H^(final)[35] = weighted_sum(all hops)
                = [0.605, 0.425, 0.675, ..., 0.495]

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
CLASSIFIER
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

      ‚Üì Linear(64 ‚Üí 32) + BN + ReLU
      [0.55, 0.38, 0.62, ..., 0.44]  (32 dims)
      ‚Üì Linear(32 ‚Üí 15)
logits[35] = [-2.1, -1.8, 3.5, 2.1, -0.5, -1.2, ...]
              ‚Üë     ‚Üë     ‚Üë    ‚Üë
            s_306 s_307 s_308 s_309
            (0)   (1)   (2)   (3)

      ‚Üì Softmax
probs[35] = [0.01, 0.02, 0.68, 0.19, 0.01, ...]
            
      ‚Üì Argmax
prediction = 2 ‚Üí service_308

–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: 3 (service_309)
–†–µ–∑—É–ª—å—Ç–∞—Ç: ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ
```

---

## 12. –ü–æ—á–µ–º—É –∫–∞–∂–¥—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –≤–∞–∂–µ–Ω

### Encoder (Linear 2‚Üí64)
**–ó–∞—á–µ–º:** –£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
**–ë–µ–∑ –Ω–µ–≥–æ:** –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–ª–∞ –±—ã —Å 2-–º–µ—Ä–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ capacity)

### Residual Connection
**–ó–∞—á–µ–º:** –°—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ –∏ –ø–æ–º–æ—á—å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º
**–ë–µ–∑ –Ω–µ–≥–æ:** –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –º–æ–≥—É—Ç "–∑–∞—Ç—É—Ö–∞—Ç—å", —Å–ª–æ–∂–Ω–µ–µ –æ–±—É—á–∞—Ç—å –≥–ª—É–±–æ–∫—É—é —Å–µ—Ç—å

### DAGNN Propagation
**–ó–∞—á–µ–º:** **–ö–õ–Æ–ß–ï–í–û–ô –ö–û–ú–ü–û–ù–ï–ù–¢!** –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –≥—Ä–∞—Ñ—É
**–ë–µ–∑ –Ω–µ–≥–æ:** –£–∑–ª—ã "–Ω–µ –∑–Ω–∞—é—Ç" –æ —Å–æ—Å–µ–¥—è—Ö, —Ç–æ–ª—å–∫–æ –æ —Å–≤–æ–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö

### Attention –¥–ª—è hops
**–ó–∞—á–µ–º:** –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Ä–∞–∑–Ω—ã—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
**–ë–µ–∑ –Ω–µ–≥–æ:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –±—ã —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π hop (—Ç–µ—Ä—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é)

### Classifier
**–ó–∞—á–µ–º:** –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
**–ë–µ–∑ –Ω–µ–≥–æ:** –ò–º–µ–ª–∏ –±—ã —Ç–æ–ª—å–∫–æ –≤–µ–∫—Ç–æ—Ä—ã, –∞ –Ω–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤

---

## 13. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏

### –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ DAGNN-Improved:

```python
# Encoder
lin1: 2 √ó 64 + 64 = 192
bn1: 64 √ó 2 = 128

# Residual
lin2: 64 √ó 64 + 64 = 4160
bn2: 64 √ó 2 = 128

# DAGNN
att: 11 (–≤–µ—Å–∞ –¥–ª—è hops)
APPNP: –Ω–µ—Ç –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—Ç–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)

# Classifier
lin3: 64 √ó 32 + 32 = 2080
bn3: 32 √ó 2 = 64
lin_out: 32 √ó 15 + 15 = 495

–ò–¢–û–ì–û ‚âà 7,312 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
```

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ:**
- GRU4Rec (50 –∫–ª–∞—Å—Å–æ–≤): ‚âà 50,000 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- DAGNN (15 –∫–ª–∞—Å—Å–æ–≤): ‚âà 7,300 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **DAGNN –≤ 7 —Ä–∞–∑ –º–µ–Ω—å—à–µ!** ‚Üí –º–µ–Ω—å—à–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ

---

## 14. –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–Ω–∞–π–¥–µ–Ω—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ)

### DAGNN-Improved (–ª—É—á—à–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è)

```python
model = DAGNNRecommender(
    in_channels=2,
    hidden_channels=128,      # –ë–æ–ª—å—à–µ —á–µ–º –±–∞–∑–æ–≤—ã–π DAGNN (64)
    out_channels=15,
    K=15,                     # –ë–æ–ª—å—à–µ hops (vs 10)
    dropout=0.5               # –ë–æ–ª—å—à–µ dropout (vs 0.4)
)

optimizer = Adam(
    model.parameters(),
    lr=0.0005,                # –ú–µ–Ω—å—à–µ lr (vs 0.001)
    weight_decay=5e-4         # –ë–æ–ª—å—à–µ weight decay (vs 1e-4)
)

# Loss: Focal Loss (70%) + Label Smoothing (30%)
focal_loss = FocalLoss(gamma=2.0, alpha=class_weights)
smooth_loss = LabelSmoothingLoss(smoothing=0.1)
loss = 0.7 * focal_loss + 0.3 * smooth_loss

epochs = 200
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç: nDCG = 0.6814** üèÜ

---

## 15. –í—ã–≤–æ–¥—ã

### –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã DAGNN:

1. **edge_index** - —Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
   - –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≥—Ä–∞—Ñ–∞
   - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ propagation
   - –ë–µ–∑ –Ω–µ–≥–æ DAGNN –Ω–µ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å

2. **Propagation** - —è–¥—Ä–æ –º–æ–¥–µ–ª–∏
   - –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –≥—Ä–∞—Ñ—É
   - K hops ‚Üí –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç –¥–∞–ª—å–Ω–∏—Ö —É–∑–ª–æ–≤
   - Teleport ‚Üí —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

3. **Attention** - —É–º–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
   - –ú–æ–¥–µ–ª—å —Å–∞–º–∞ —É—á–∏—Ç—Å—è, –∫–∞–∫–∏–µ hops –≤–∞–∂–Ω—ã
   - –†–∞–∑–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–∞—é—Ç —Ä–∞–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

4. **Residual** - —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
   - –ü–æ–º–æ–≥–∞–µ—Ç –æ–±—É—á–µ–Ω–∏—é
   - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

### –ü–æ—á–µ–º—É DAGNN —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ DAG:

- ‚úÖ –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è propagation (–ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é —Ä–µ–±–µ—Ä)
- ‚úÖ –£—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- ‚úÖ –ú–Ω–æ–≥–æ—à–∞–≥–æ–≤–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ (K hops)
- ‚úÖ Teleport –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç "—Ä–∞–∑–º–∞–∑—ã–≤–∞–Ω–∏–µ" –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

### –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –º–∞–ª–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞:

- ‚úÖ 15 –≤—ã—Ö–æ–¥–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ (—Ç–æ–ª—å–∫–æ —Å–µ—Ä–≤–∏—Å—ã)
- ‚úÖ –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≥—Ä–∞—Ñ –ë–ï–ó –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–π (97 —Ä–µ–±–µ—Ä)
- ‚úÖ –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (2 —Ñ–∏—á–∏)
- ‚úÖ Residual connections
- ‚úÖ Focal Loss –¥–ª—è –±–æ—Ä—å–±—ã —Å –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å—é

---

*–§–∞–π–ª —Å–æ–∑–¥–∞–Ω: 2025-10-24*  
*–í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏: DAGNN v4.2 (Optimized)*

